{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules & packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able tu use declarations and definitions of an existing module, you should use the *import* clause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import module [as alias]\n",
    "\n",
    "#example\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the import command as above to import additional modules or packages for the future of this pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the plotting module matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#the numpy package for scientific computing and also the great tool for manipulate arrays\n",
    "import numpy as np\n",
    "\n",
    "#the image processing package skimage and ndimage from scipy\n",
    "import skimage\n",
    "import scipy.ndimage as ndi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing & Handling Image Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Background**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images are essentially a matrix of numbers.   \n",
    "Image processing means simply to carry out mathematical operations on these numbers.   \n",
    "The ideal object for storing and manipulating matrix of numbers is the array.   \n",
    "Many mathematical operations are well defined on arrays and can be computed quickly by vector-based computation.   \n",
    "Arrays can have any number of dimensions (or \"axis\"). For example, a 2D array could represent the x and y axis of a grayscale image, a 3D array could contain a z-stack (zyx), a 4D array could also have multiple channels for each image (czyx) and a 5D array could have time on top of that (tczyx)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the instructions in the comments below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (i) Specify the filename\n",
    "# Create a string variable of the file to be imported ('FITC.jpeg')\n",
    "# Suggested name for the variable: filename_1\n",
    "# Note: If the file is not in your current working directory, the filename variable must contain the \n",
    "#       entire path to the file, for example r'/home/cedric/data/FITC.jpeg'. Note the r at\n",
    "#       the beginning of the string: it designates this string as a \"raw\" string, which helps to\n",
    "#       avoid problems with slashes and other special symbols\n",
    "filename_1 = r'/home/cedric/Documents/Atelier_Mifobio/jupyter-workshop-mifobio-2018/exercices/PK-11B-pl1/Well-C003/FITC.jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a string variable of the file to be imported ('Hoechst.jpeg')\n",
    "filename_2 = r'/home/cedric/Documents/Atelier_Mifobio/jupyter-workshop-mifobio-2018/exercices/PK-11B-pl1/Well-C003/Hoechst.jpeg'\n",
    "\n",
    "# Create a string variable of the file to be imported ('Tritc.jpeg')\n",
    "filename_3 = r'/home/cedric/Documents/Atelier_Mifobio/jupyter-workshop-mifobio-2018/exercices/PK-11B-pl1/Well-C003/Tritc.jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (ii) Load the images\n",
    "# Import the function 'imread' from the module 'skimage.io'\n",
    "from skimage.io import imread\n",
    "\n",
    "# Load 'FITC.jpeg' and store it in a variable.\n",
    "# Suggested name for the variable: fitc\n",
    "fitc = imread(filename_1)\n",
    "\n",
    "# Load 'Hoechst.jpeg' and store it in a variable.\n",
    "# Suggested name for the variable: hoechst\n",
    "hoechst = imread(filename_2)\n",
    "\n",
    "# Load 'Tritc.jpeg' and store it in a variable.\n",
    "# Suggested name for the variable: tritc\n",
    "tritc = imread(filename_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (iii) Check the data represention of the images\n",
    "# Check that 'fitc', 'hoechst', 'tritc' is a variable of type 'ndarray' - use Python's built-in function 'type'.\n",
    "print(\"Fitc is of type:\"),type(fitc)\n",
    "print(\"Hoechst is of type:\"),type(hoechst)\n",
    "print(\"Tritc is of type:\"),type(tritc)\n",
    "\n",
    "# Print the shape of the array using the numpy-function 'shape'. \n",
    "print(\"Fitc has shape:\"),fitc.shape\n",
    "print(\"Hoechst has shape:\"),hoechst.shape\n",
    "print(\"Tritc has shape:\"),tritc.shape\n",
    "\n",
    "# Check the datatype of the individual numbers in the array. You can use the array attribute 'dtype' to do so.\n",
    "print(\"Fitc values are of type:\"),fitc.dtype\n",
    "print(\"Hoechst values are of type:\"),fitc.dtype\n",
    "print(\"Tritc values are of type:\"),tritc.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(iv) Normalize images\n",
    "#To compare image between them we can use numpy.iinfo function that get the range for n bits and \n",
    "# then divide the data by the max range to normalize image.\n",
    "\n",
    "info = np.iinfo(hoechst.dtype)\n",
    "hoechst = hoechst.astype(np.float64) / info.max\n",
    "\n",
    "info = np.iinfo(fitc.dtype)\n",
    "fitc = fitc.astype(np.float64) / info.max\n",
    "\n",
    "info = np.iinfo(tritc.dtype)\n",
    "tritc = tritc.astype(np.float64) / info.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (v) Look at the images to check that all is OK.\n",
    "# Use pyplot's functions plt.imshow followed by plt.show. \n",
    "# Check the documentation for plt.imshow and note the parameters that can be specified, such as the color map (cmap)\n",
    "# and interpolation. Since you are working with scientific data, interpolation is unwelcome, so you should set it to\n",
    "# 'none'. The most common cmap for grayscale images is naturally 'gray'.\n",
    "# You may also want to adjust the size of the figure. You can do this by preparing the figure canvas with\n",
    "# the function plt.figure before calling plt.imshow. The canvas size is adjusted using the keyword argument\n",
    "# figsize when calling plt.figure.\n",
    "plt.figure(figsize=(14,14))\n",
    "plt.imshow(fitc,interpolation='none',cmap='gray')\n",
    "plt.show()\n",
    "plt.figure(figsize=(14,14))\n",
    "plt.imshow(hoechst,interpolation='none',cmap='gray')\n",
    "plt.show()\n",
    "plt.figure(figsize=(14,14))\n",
    "plt.imshow(tritc,interpolation='none',cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# (v) Create a composite image.\n",
    "# First get a colored image by using the module gray2rgb from skimage.color.\n",
    "# Apply different colors to the three channels. A green channel to tritc image, a blue channel to hoechst image, \n",
    "# a red channel to fitc image\n",
    "# You can visualize the different channels in the same image by merging them; Merging channels by using the operator + \n",
    "# and so create a new variable composite as example. Then use the functions used above \n",
    "# to display the creating image. \n",
    "from skimage.color import gray2rgb\n",
    "\n",
    "fitc_rgb = gray2rgb(fitc)\n",
    "hoechst_rgb = gray2rgb(hoechst)\n",
    "tritc_rgb = gray2rgb(tritc)\n",
    "\n",
    "tritc_green = tritc_rgb * [0,1,0]\n",
    "hoechst_blue = hoechst_rgb * [0,0,1]\n",
    "fitc_red = fitc_rgb * [1,0,0]\n",
    "\n",
    "composite = tritc_green + hoechst_blue + fitc_red\n",
    "plt.figure(figsize=(14,14))\n",
    "plt.imshow(composite,interpolation='none',cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "composite.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing nuclei mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Background**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of image preprocessing is to prepare or optimize the images to make further analysis easier. The specific preprocessing steps used in a pipeline depend on the type of image, the microscopy technique used, the image quality, and the desired downstream analysis.   \n",
    "In this pipeline we will be using a median filter then a background substraction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Median filtering is useful as a smoothing technique for reduce noice.   \n",
    "The median filter considers each pixel in the image in turn and looks at its nearby neighbors to decide whether or not it is representative of its surroundings. Instead of simply replacing the pixel value with the mean of neighboring pixel values, it replaces it with the median of those values. The median is calculated by first sorting all the pixel values from the surrounding neighborhood into numerical order and then replacing the pixel being considered with the middle pixel value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the instructions in the comments below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (i) Create a variable for the size of smoothing filter. \n",
    "#Either the sizes of a rectangular kernel or the footprint of the kernel must be provided. \n",
    "#The size parameter, if provided, must be a sequence of sizes or a single number in which case the size of \n",
    "#the filter is assumed to be equal along each axis. \n",
    "#The footprint if provided, must be an array that defines the shape of the kernel by its non-zero elements.\n",
    "size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (ii) Perform the smoothing on the image\n",
    "# To do so, use the median filter function 'ndi.filters.median_filter' from the \n",
    "# image processing package ndimage, which was imported at the start of the tutorial. \n",
    "# Check out the documentation of scipy to see how to implement this function. \n",
    "# Allocate the output to a new variable.\n",
    "hoechst_smooth = ndi.filters.median_filter(hoechst,size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (iii) Visualize the result using plt.imshow and plt.show\n",
    "plt.figure(figsize=(14,14))\n",
    "plt.imshow(hoechst_smooth,interpolation='none',cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otsu's method is used to perform clustering based image thresholding. \n",
    "Assuming a bi-modal intensity distribution, pixels are separate into foreground and backround. \n",
    "The optimal threshold value to separate the two classes is determined by minimizing the combined intra-class variance \n",
    "or by maximizing the combined inter-class variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the instructions in the comments below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(i) Threshold the median-smoothed original image using the otsu method to obtain the nuclei mask.\n",
    "# Set pixels with higher values in the original than in the bg to 1 and pixels with lower values to 0. \n",
    "# You can use a \"relational operator\" to do this, since numpy arrays will automatically perform element-wise\n",
    "# comparisons when compared to other arrays of the same shape.\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "nmask = np.zeros(hoechst_smooth.shape, dtype = bool)\n",
    "nmask[hoechst_smooth > threshold_otsu(hoechst_smooth)] = 1\n",
    "\n",
    "# (ii) Visualize the result using plt.imshow and plt.show\n",
    "plt.figure(figsize=(14,14))\n",
    "plt.imshow(nmask, cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving Masks with Binary Morphology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Background**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Morphological operations such as erosion, dilation, closing and opening are common tools used (among other things) to improve masks after they are generated by thresholding.   \n",
    "They can be used to fill small holes, remove noise, increase or decrease the size of an object, or smoothen mask outlines.   \n",
    "Most morphological operations are - once again - simple kernel functions that are applied at each pixel of the image based on their neighborhood as defined by a structuring element (SE). For example, dilation simply assigns to the central pixel the maximum pixel value within the neighborhood; it is a maximum filter. Conversely, erosion is a minimum filter. Additional options emerge from combining the two: morphological closing, for example, is a dilation followed by an erosion. This is used to fill in gaps and holes or smoothing mask outlines without significantly changing the mask's area.   \n",
    "Finally, there are also some more complicated morphological operations, such as hole filling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the instructions in the comments below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (i) Create a diamond-shaped structuring element and asign it to a new variable.\n",
    "# Structuring elements are small binary images that indicate which pixels \n",
    "# should be considered as the 'neighborhood' of the central pixel.\n",
    "# You can use skimage.morphology.diamond to create diamond-shaped structuring element\n",
    "\n",
    "from skimage.morphology import diamond\n",
    "se = diamond(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (ii) Try morphological operations to further improve the membrane mask\n",
    "# The various operations are available in skimage, for example skimage.morphology.closing and ndimage for hole filling\n",
    "\n",
    "from skimage.morphology import closing\n",
    "from skimage.morphology import opening\n",
    "\n",
    "nmask = opening(closing(nmask, se),se)\n",
    "nmask = ndi.binary_fill_holes(nmask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (iii) Visualize the result using plt.imshow and plt.show\n",
    "plt.figure(figsize=(14,14))\n",
    "plt.imshow(nmask, cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing cell mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (i) Adjust Brightness and Contrast\n",
    "# Before compute cell mask, try to increase the brigtness and the contrast of the image. \n",
    "# Note: Play with mathematical operator\n",
    "# operator '+' or '-' for the brigthness\n",
    "# operator '*' for contrast\n",
    "\n",
    "ntritc = tritc * 2.82 - 0.17\n",
    "nfitc = fitc * 5.03 - 0.35\n",
    "nhoechst = hoechst * 2.99 - 0.15\n",
    "\n",
    "#(ii) Visualize the result after create a mix image using plt.imshow and plt.show\n",
    "mix = nfitc+ntritc+nhoechst\n",
    "plt.figure(figsize=(14,14))\n",
    "plt.imshow(mix, cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(iii) Do you improve the light of the image by playing with the gamma.\n",
    "# test operator ^ (** in python) to apply gamma correction\n",
    "mix_2 = (nfitc**2+ntritc**2+nhoechst**2)**0.5\n",
    "\n",
    "#(iv) Visualize the result\n",
    "plt.figure(figsize=(14,14))\n",
    "plt.imshow(mix_2, cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2d convolution filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear filtering is useful to perform low-pass filtering (to blur images, remove noise...) and high-pass filtering (to detect edges, sharpen images)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (i) Create a cross-shaped structuring element and asign it to a new variable.\n",
    "# Structuring elements are small binary images that indicate which pixels \n",
    "# should be considered as the 'neighborhood' of the central pixel.\n",
    "# create a matrix with 3 columns and 3 rows as below\n",
    "# 0 1 0\n",
    "# 1 2 1\n",
    "# 0 1 0\n",
    "# then divide all values by 6 to obtain a float type matrix. Use the function matrix from numpy. \n",
    "se = np.matrix([[0,1,0],[1,2,1],[0,1,0]], dtype='float')/6\n",
    "\n",
    "# (ii) import signal from scipy to get the convolve2d function for execute the 2d convolution filter on the image. \n",
    "# Read the documentation to get more details on the parameters of the function.\n",
    "from scipy import signal\n",
    "\n",
    "cmask = signal.convolve2d(mix_2, se, boundary=\"wrap\", mode=\"same\") >= 0.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(iii) display the result\n",
    "plt.imshow(cmask,interpolation='none',cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (iii) Create a diamond-shaped structuring element and asign it to a new variable.\n",
    "# Structuring elements are small binary images that indicate which pixels \n",
    "# should be considered as the 'neighborhood' of the central pixel.\n",
    "# You can use skimage.morphology.diamond to create diamond-shaped structuring element\n",
    "se = diamond(1)\n",
    "\n",
    "# (iv) Use morphology operation like closing to improve image\n",
    "cmask = closing(cmask, se)\n",
    "\n",
    "plt.imshow(cmask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# segmenting nuclei using watershed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Background**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm identifies and separates objects that stand out of the background (zero). It inverts the image and uses water to fill the resulting valleys (pixels with high intensity in the source image) until another object or background is met. The deepest valleys become indexed first, starting from 1.   \n",
    "An array of seeds contains a few pixels at the center of each cell labeled by a unique ID number and otherwise surrounded by zeros. The expansion algorithm will start from these central pixels and grow outward until all zeros are overwritten by an ID label. In the case of watershed expansion, one can imagine the seeds as the sources from which water pours into the cells and starts filling them up.   \n",
    "Here, we will use a distance transform and local maxima for seeding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (i) Distance transform on thresholded membranes\n",
    "# Use the function ndi.distance_transform_edt.\n",
    "dist_transf = ndi.distance_transform_edt(nmask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (ii) Visualize the output and understand what you are seeing.\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(dist_transf,interpolation='none',cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (iii) Dilate the distance threshold\n",
    "# Use ndi.filters.maximum_filter to dilate the distance transform.\n",
    "i = 10\n",
    "struct = (np.mgrid[:i,:i][0] - np.floor(i/2))**2 + (np.mgrid[:i,:i][1] - np.floor(i/2))**2 <= np.floor(i/2)**2\n",
    "dist_trans_dil = ndi.filters.maximum_filter(dist_transf, footprint=struct) \n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(dist_trans_dil, interpolation='none', cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (iv) Retrieve the local maxima (the 'peaks') in the distance transform\n",
    "# Use the function peak_local_max from the module skimage.feature.\n",
    "from skimage.feature import peak_local_max\n",
    "seeds = peak_local_max(dist_trans_dil, indices=False, min_distance=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (v) Visualize the output\n",
    "# you can first plot the original input (or the smoothed) image and\n",
    "# then plot the seeds on top of it before showing both with 'plt.show'.\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(hoechst_smooth, interpolation='none', cmap='gray')\n",
    "plt.imshow(np.ma.array(seeds,mask=seeds==0),interpolation='none',cmap='autumn')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (vi) Label the seeds\n",
    "# Use connected component labeling to give each cell seed a unique ID number.\n",
    "seeds_labeled = ndi.label(seeds)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (vii) Perform watershed\n",
    "# Use the function watershed from the module skimage.morphology.\n",
    "# Use the labeled nuclei seeds and the smoothed nuclei image as input.\n",
    "from skimage.morphology import watershed\n",
    "ws = watershed(hoechst_smooth,seeds_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (viii) Show the result as transparent overlay over the smoothed input image\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(hoechst_smooth, interpolation='none', cmap='gray')\n",
    "plt.imshow(ws,interpolation='none',cmap='prism',alpha=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# segmenting cells using Voronoi tesselation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find boundaries between adjacent regions in an image, where seeds have been already identified in the individual regions to be segmented. The method finds the Voronoi region of each seed on a manifold with a metric controlled by local image properties. The method is motivated by the problem of finding the borders of cells in microscopy images, given a labelling of the nuclei in the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (i) The label function from skimage.measure module finds every connected set of pixels other than the background, \n",
    "# and relabels these sets with a unique increasing integer.\n",
    "from skimage.measure import label\n",
    "markers_nuc = label(nmask, connectivity=2, return_num=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (ii) We apply a sobel filter from skimage.filters to detect edges from cell body and serve as input \n",
    "# for the voronoi tesselation algorithm. \n",
    "from skimage.filters import sobel\n",
    "\n",
    "fsobel = np.empty_like(mix_2)\n",
    "fsobel = sobel(mix_2)\n",
    "\n",
    "# (iii) Visualize the output\n",
    "plt.imshow(fsobel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (iv) This algo is implemented in centrosome package, an open source image processing library.\n",
    "from centrosome.propagate import propagate\n",
    "cell_seg,_ = propagate(image=fsobel, labels=markers_nuc[0], mask=cmask, weight=1)\n",
    "\n",
    "# (v) Visualize the output. Focus on boundaries between labeled \n",
    "# regions highlighted thanks to mark_boundaries from skimage.segmentation and draw contour lines \n",
    "# for nuclei thanks to contour from matplotlib.pyplot.\n",
    "from skimage.segmentation import mark_boundaries\n",
    "plt.imshow(mark_boundaries(composite, cell_seg))\n",
    "plt.contour(nmask, colors = 'r', linewidths = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantification of cell features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**background**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ultimate goal of image segmentation is of course the extraction of quantitative measurements, in this case on a single-cell level. Measures of interest can be based on intensity (in different channels) or on the size and shape of the cells.\n",
    "\n",
    "we will extract the following:\n",
    "\n",
    "    Cell ID (so all other measurements can be traced back to the cell that was measured)\n",
    "    Mean intensity of each cell, for each channel\n",
    "    The cell area i.e. the number of pixels that make up the cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the instructions below to extract measurements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (i) Create a dictionary that contains a key-value pairing for each measurement\n",
    "# The keys should be a strings describing the type of measurement (e.g. 'cell_tubulin_mean') \n",
    "# and the values should be empty lists. These empty lists will be filled with the results of \n",
    "# the measurements and the dictionary will make it easy to work with this data.\n",
    "results = {\"cell_id\":[],\n",
    "           \"cell_tubulin_mean\":[],\n",
    "           \"cell_actin_mean\":[],\n",
    "           \"cell_area\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (ii) Record the measurements for each cell\n",
    "# Iterate over the segmented cells (np.unique).\n",
    "# Inside the loop, create a mask for the current cell and use it to extract the measurements listed above. \n",
    "# Add them to the appropriate list in the dictionary using the list.append method.\n",
    "# Hint: Remember that you can get out all the values within a masked area by indexing the image \n",
    "#       with the mask. For example, np.mean(image[cell_mask]) will return the mean of all the \n",
    "#       intensity values of 'image' that are masked by 'cell_mask'.\n",
    "\n",
    "# Iterate over cell IDs\n",
    "for cell_id in np.unique(cell_seg)[1:]:\n",
    "\n",
    "    # Mask the current cell\n",
    "    cell_mask = cell_seg==cell_id\n",
    "    \n",
    "    # Get the measurements\n",
    "    # Note: the .item() method ensures that the resulting number is converted from a numpy number object\n",
    "    #       (e.g. type np.float) to a native python number object (e.g. type float). For most purposes,\n",
    "    #       this is irrelevant, but for saving data in a python object as we do later on, it is useful\n",
    "    #       to use native python objects only.\n",
    "    results[\"cell_id\"].append(cell_id.item())\n",
    "    results[\"cell_area\"].append(np.sum(cell_mask).item())\n",
    "    results[\"cell_tubulin_mean\"].append(np.mean(tritc[cell_mask]).item())\n",
    "    results[\"cell_actin_mean\"].append(np.mean(fitc[cell_mask]).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (iii) Print the results and check that they make sense\n",
    "for key in results.keys(): print key, '\\n', results[key], '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing output files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Background**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step of the pipeline shows how to write output of the pipeline to files.\n",
    "\n",
    "Data can be saved to files in a human-readable format such as text files (e.g. to import into Excel), in a format readable for other programs such as tif-images (e.g. to view in Fiji)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the instructions below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (i) Write one or more of the images you produced to a tif file\n",
    "# Use the function imsave from the tifffile module. Make sure that the array you are writing\n",
    "# is of integer type. If necessary, you can use the method 'img_as_uint'.\n",
    "# After writing the file, load it into Fiji and check that everything worked as intended.\n",
    "from tifffile import imsave\n",
    "from skimage import img_as_uint\n",
    "\n",
    "icomposite = img_as_uint(image= composite)\n",
    "imsave(\"composite.tif\",icomposite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (ii) writing files to omero server\n",
    "# - 1/ if you not already connected, connect you to omero server\n",
    "# - 2/ get information on you\n",
    "# - 3/ get project/dataset of mifobio group\n",
    "# - 4/ write file to omero server\n",
    "\n",
    "from omero.gateway import BlitzGateway\n",
    "from numpy import array\n",
    "import config\n",
    "\n",
    "HOST = '10.5.0.156'\n",
    "PORT = 4064\n",
    "USERNAME = config.USERNAME\n",
    "PASSWORD = config.PASSWORD\n",
    "conn = BlitzGateway(USERNAME, PASSWORD, host=HOST, port=PORT)\n",
    "conn.connect()\n",
    "conn.setSecure(True)\n",
    "\n",
    "user = conn.getUser()\n",
    "print \"Current user:\"\n",
    "print \"  ID:\", user.getId()\n",
    "print \"  Username:\", user.getName()\n",
    "print \"  Full Name:\", user.getFullName()\n",
    "print \"Member of:\"\n",
    "for g in conn.getGroupsMemberOf():\n",
    "    print \"  ID:\", g.getName(), \" Name:\", g.getId()\n",
    "group = conn.getGroupFromContext()\n",
    "print \"Current group: \", group.getName()\n",
    "\n",
    "def print_obj(obj, indent=0):\n",
    "    \"\"\"\n",
    "    Helper method to display info about OMERO objects.\n",
    "    Not all objects will have a \"name\" or owner field.\n",
    "    \"\"\"\n",
    "    print \"\"\"%s%s:%s  Name:\"%s\" (owner=%s)\"\"\" % (\n",
    "        \" \" * indent,\n",
    "        obj.OMERO_CLASS,\n",
    "        obj.getId(),\n",
    "        obj.getName(),\n",
    "        obj.getOwnerOmeName())\n",
    "\n",
    "my_exp_id = conn.getUser().getId()\n",
    "\n",
    "#switch group\n",
    "conn.SERVICE_OPTS.setOmeroGroup(3)\n",
    "\n",
    "for project in conn.getObjects(\"Project\", opts={'owner': my_exp_id,\n",
    "                                            'group': 3,\n",
    "                                            'order_by': 'lower(obj.name)',\n",
    "                                            'limit': 5, 'offset': 0}):\n",
    "    print_obj(project)\n",
    "    # We can get Datasets with listChildren, since we have the Project already.\n",
    "    # Or conn.getObjects(\"Dataset\", opts={'project', id}) if we have Project ID\n",
    "    for dataset in project.listChildren():\n",
    "        print_obj(dataset, 2)\n",
    "        for image in dataset.listChildren():\n",
    "            print_obj(image, 4)\n",
    "\n",
    "#datasets = conn.getObjects(\"Dataset\", opts={'Project': 2, 'group': 'mifobio'})\n",
    "dataset = conn.getObject(\"Dataset\", 3)\n",
    "\n",
    "#for dataset in datasets:\n",
    "size_x, size_y, size_z, size_c, size_t = 1024, 510, 1, 3, 1\n",
    "plane1 = array(composite[:,:,0])\n",
    "plane2 = array(composite[:,:,1])\n",
    "plane3 = array(composite[:,:,2])\n",
    "planes = [plane1, plane2, plane3]\n",
    "\n",
    "def plane_gen():\n",
    "    for p in planes:\n",
    "        yield p\n",
    "\n",
    "desc = \"Image imported from a local image\"\n",
    "#print dataset\n",
    "\n",
    "i = conn.createImageFromNumpySeq(\n",
    "plane_gen(), \"merge image\", size_z, size_c, size_t, description=desc, dataset=dataset)\n",
    "\n",
    "print 'Created new Image:%s Name:\"%s\"' % (i.getId(), i.getName())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (v) Write a tab-separated text file of the results dict\n",
    "# The most generic way of saving numerical results is a simple text file. It can be imported into \n",
    "# pretty much any other program.\n",
    "\n",
    "# To write normal text files, open an empty file object in write mode ('w') using the 'with'-statement.\n",
    "with open('cell_results.txt','w') as outfile:\n",
    "\n",
    "    # Use the file_object.write(string) method to write strings to the file. First write the header of the\n",
    "    # date (the result dict keys), separated by tabs ('\\t'). It makes sense to first generate a complete\n",
    "    # string with all the headers and then write this string to the file. Note that you will need to \n",
    "    # explicitly write 'newline' characters ('\\n') at the end of the line to switch to the next line.\n",
    "    sorted_keys = sorted(results.keys())\n",
    "    header_string = '\\t'.join(sorted_keys) + '\\n'\n",
    "    outfile.write(header_string)\n",
    "\n",
    "    # After writing the headers, iterate over all the cells saved and write the data to the file by\n",
    "    # creating strings similar to the header string.\n",
    "    for index in range(len(results['cell_id'])):\n",
    "        data_string = '\\t'.join([str(results[key][index]) for key in sorted_keys]) + '\\n'\n",
    "        outfile.write(data_string)\n",
    "        \n",
    "# After writing the data, have a look at the output file in a text editor or in a spreadsheet\n",
    "# program like Excel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the pipeline to a function:\n",
    "\n",
    "Convert the entire pipeline into a function that accepts a filename as input, runs everything, and returns the final segmentation and the results dictionary. To do this, you must:\n",
    "\n",
    "    Add the function definition statement at the beginning of the script (after the imports)\n",
    "    Replace the 'hard-coded' filename by a variable that is accepted by the function\n",
    "    Indent all the code\n",
    "    Add a return statement at the end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the function and running it for multiple input files:\n",
    "\n",
    "To actually run the pipeline function for multiple input files, we need to do the following:\n",
    "\n",
    "    Iterate over all the filenames in a directory\n",
    "    For each filename, call the pipeline function\n",
    "    Collect the returned results\n",
    "\n",
    "Follow the instructions in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (i) Test if your pipeline function actually works\n",
    "# Import your function using the normal python syntax for imports, like this:\n",
    "#   from your_module import your_function\n",
    "# Run the function and visualize the resulting segmentation. Make sure everything\n",
    "# works as intended.\n",
    "\n",
    "# Import\n",
    "from tuto_pipeline import run_pipeline\n",
    "\n",
    "# Run\n",
    "filename_1 = r'/home/cedric/Documents/Atelier_Mifobio/jupyter-workshop-mifobio-2018/exercices/PK-11B-pl1/Well-C003/FITC.jpeg'\n",
    "filename_2 = r'/home/cedric/Documents/Atelier_Mifobio/jupyter-workshop-mifobio-2018/exercices/PK-11B-pl1/Well-C003/Hoechst.jpeg'\n",
    "filename_3 = r'/home/cedric/Documents/Atelier_Mifobio/jupyter-workshop-mifobio-2018/exercices/PK-11B-pl1/Well-C003/Tritc.jpeg'\n",
    "\n",
    "seg, results = run_pipeline(filename_1, filename_2, filename_3)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(np.zeros_like(seg),interpolation='none',cmap='gray',vmax=1)  # Black background\n",
    "plt.imshow(np.ma.array(seg,mask=seg==0),interpolation='none',cmap='prism')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (ii) Get all relevant filenames from the directory\n",
    "# Use the function 'walk' from the module 'os' to get a list of all the files\n",
    "# in a directory.\n",
    "\n",
    "# Get all files\n",
    "from os import walk\n",
    "target_files = []\n",
    "wellnames = []\n",
    "for root,_,filenames in walk(\"/home/cedric/Documents/Atelier_Mifobio/jupyter-workshop-mifobio-2018/exercices/PK-11B-pl1/\"):\n",
    "    for filename in filenames:\n",
    "        wellnames.append(root)\n",
    "        target_files.append(os.path.join(root, filename))\n",
    "\n",
    "for x in wellnames:\n",
    "    print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# (iii) Iterate over the relevant input filenames and run the pipeline function\n",
    "# Be sure to collect the output of the pipeline function in a way that allows\n",
    "# you to trace it back to the file it came from. You could for example use a\n",
    "# dictionary with the wellnames as keys.\n",
    "all_seg = {}\n",
    "all_results = {}\n",
    "\n",
    "\n",
    "\n",
    "for x in range(0,18,3):\n",
    "    seg,results = run_pipeline(target_files[x+2],target_files[x+1], target_files[x+0])\n",
    "    all_seg[wellnames[x]] = seg\n",
    "    all_results[wellnames[x]] = results\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(np.zeros_like(all_seg['/home/cedric/Documents/Atelier_Mifobio/jupyter-workshop-mifobio-2018/exercices/PK-11B-pl1/Well-A003']),interpolation='none',cmap='gray',vmax=1)  # Black background\n",
    "plt.imshow(np.ma.array(all_seg['/home/cedric/Documents/Atelier_Mifobio/jupyter-workshop-mifobio-2018/exercices/PK-11B-pl1/Well-A003'],mask=all_seg['/home/cedric/Documents/Atelier_Mifobio/jupyter-workshop-mifobio-2018/exercices/PK-11B-pl1/Well-A003']==0),interpolation='none',cmap='prism')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in all_results.keys(): print key, '\\n', all_results[key], '\\n'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
